{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bitcoin_user_cluster",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU9mk3tuYGuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import random\n",
        "import os\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from queue import *\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joDtHn1iYlCw",
        "colab_type": "text"
      },
      "source": [
        "**Data collection**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1.   Data for bitcoin is queried form google Bigdata.\n",
        "2.   I have used my authentication.\n",
        "3.   I have already saved the csv files so there is no      need to run the query again\n",
        "4.   The user can skip to preprocessing directely.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz2N8UeGZSN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bq_helper import BigQueryHelper\n",
        "# this bq_helper can be installed with pip install -e git+https://github.com/SohierDane/BigQuery_Helper#egg=bq_helper\n",
        "\n",
        "auth_path = \"drive/My Drive/bitcoin/bitcoin 2-a8cb46913b9c.json\"\n",
        "# auth_path is location of your google cloud json file. needed for querying.\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]= auth_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KohR7-CQbEKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bq_assist = BigQueryHelper(active_project= \"bigquery-public-data\", dataset_name = \"bitcoin_blockchain\")\n",
        "# I extract tables from bitcoin_blockchain dataset  \n",
        "bq_assist.list_tables()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRE1Ml6Qbd5f",
        "colab_type": "text"
      },
      "source": [
        "**There are two tables in the dataset**\n",
        "1.   Blocks\n",
        "2.   Transaction\n",
        "---\n",
        "I am primarily interested in Transaction as we cluster bitcoin addresses on the basis of the amount of money exchanged.  \n",
        "\n",
        "---\n",
        "We want to extract 3 information.\n",
        "\n",
        "\n",
        "1.   input_address\n",
        "2.   output_address\n",
        "3.   amount of bitcoin transferred\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLtQ8OsWbWsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT\n",
        "    inputs.input_pubkey_base58 AS input_key,\n",
        "    outputs.output_pubkey_base58 AS output_key,\n",
        "    SUM(outputs.output_satoshis) as satoshis\n",
        "FROM `bigquery-public-data.bitcoin_blockchain.transactions`\n",
        "    JOIN UNNEST (inputs) AS inputs\n",
        "    JOIN UNNEST (outputs) AS outputs\n",
        "WHERE timestamp >= 1293840000000\n",
        "    AND timestamp <= 1325376000000\n",
        "    \n",
        "    AND inputs.input_pubkey_base58 IS NOT NULL\n",
        "    AND outputs.output_pubkey_base58 IS NOT NULL\n",
        "GROUP BY input_key, output_key\n",
        "LIMIT 2500000\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRTZTDZmcnhR",
        "colab_type": "text"
      },
      "source": [
        "This query extracts all the transactions made in 2011.\n",
        "\n",
        "\n",
        "1.   Grouped by input_address and output_address            (transaction amount as added up)\n",
        "2.   We remove transactions with input or output as        None(These are generally online betting games)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "I have extracted 3 data sets.\n",
        " \n",
        "\n",
        "1.   data for 2010\n",
        "2.   data for 2011\n",
        "3.   data for first 2 months for 2011\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAb8bTVecmH_",
        "colab_type": "code",
        "outputId": "6601b4c4-a6a9-4cba-aac1-06a188d8bf73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "bq_assist.estimate_query_size(query)\n",
        "# estimation query size before running "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64.56548567861319"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcKjRxYeeIYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_save_path = \"drive/My Drive/bitcoin/2011_transactions.csv\"\n",
        "#df = bq_assist.query_to_pandas_safe(query, max_gb_scanned= 70)  #uncomment if you want to run the query again\n",
        "#df.to_csv(data_save_path , index = None)\n",
        "\n",
        "\n",
        "# running this wil get the data into df as a pandas dataframe and finally store it at data_save_path as csv\n",
        "#beware its will be a very large dataset\n",
        "#There we almost 60k transactions per day in 2011!!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9ozfL0SgmHP",
        "colab_type": "text"
      },
      "source": [
        "# Processing the data\n",
        "The goal is to make both directed and undirected graphs for analyzing the data and clusterring addresses\n",
        "\n",
        "The graphs have all the unique addresses as nodes and transactions as weighted edges.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lvsYfuIfbku",
        "colab_type": "code",
        "outputId": "08dd4ecd-fb53-4fab-aab4-ee71a7b2ed16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df = pd.read_csv(data_save_path)\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_key</th>\n",
              "      <th>output_key</th>\n",
              "      <th>satoshis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16xXj3T5ujZ3LtxPNza7eEz6fbk62YiWb6</td>\n",
              "      <td>1GBpxPrToaqBsgiL32vdRf39EmevuzeYCy</td>\n",
              "      <td>991898940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1BQg9aXxS88Enpa74ySUmMZWaKEb633GeM</td>\n",
              "      <td>1L5Kp632Cf6oe4G2CvK3x8MzVpbsWcaXHo</td>\n",
              "      <td>1576621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1PJnjo4n2Rt5jWTUrCRr4inK2XmFPXqFC7</td>\n",
              "      <td>12RByqNNXmNpdUtdgV4T3k4YAW5F7oPxQA</td>\n",
              "      <td>526000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>179BCw6ZsHJMzQcgLcFnFN8unoFqtq4QZm</td>\n",
              "      <td>1fG1298c7NeuV8N78dBNVVmeWDF5fzQqe</td>\n",
              "      <td>7000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1DkrM9zhYuTWpYKqqniD1y7cF8oRVt896b</td>\n",
              "      <td>1JPzWjaEBfqcCKX8Y8J6P5QPu6bQ9RGfSZ</td>\n",
              "      <td>125684937</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            input_key  ...   satoshis\n",
              "0  16xXj3T5ujZ3LtxPNza7eEz6fbk62YiWb6  ...  991898940\n",
              "1  1BQg9aXxS88Enpa74ySUmMZWaKEb633GeM  ...    1576621\n",
              "2  1PJnjo4n2Rt5jWTUrCRr4inK2XmFPXqFC7  ...  526000000\n",
              "3  179BCw6ZsHJMzQcgLcFnFN8unoFqtq4QZm  ...    7000000\n",
              "4  1DkrM9zhYuTWpYKqqniD1y7cF8oRVt896b  ...  125684937\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwBKEhkQiyWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting satoshis to bitcoin\n",
        "data = df.values.tolist()\n",
        "for i in range(len(data)):\n",
        "    data[i][2] = data[i][2]/100000000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN8oGD-SjMRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Node:\n",
        "    def __init__(self , name):\n",
        "        self.name = name\n",
        "        self.adj = []\n",
        "        self.visited = False\n",
        "        \n",
        "        \n",
        "class my_graph:\n",
        "    def __init__(self , edge_list):\n",
        "        self.edge_list = edge_list\n",
        "        self.uniq = {}\n",
        "        self.mx = 0\n",
        "        self.cluster = []\n",
        "    def create_nodes(self):\n",
        "        edge_list = self.edge_list\n",
        "        uniq = self.uniq\n",
        "        for e in edge_list:\n",
        "            if(e[0] not in uniq):\n",
        "                uniq[e[0]] = Node(e[0])\n",
        "            if(e[1] not in uniq):\n",
        "                uniq[e[1]] = Node(e[1])\n",
        "            \n",
        "    def create_graph(self):\n",
        "        self.create_nodes()\n",
        "        edge_list = self.edge_list\n",
        "        for e in edge_list:\n",
        "            self.uniq[e[0]].adj.append(self.uniq[e[1]])\n",
        "            self.uniq[e[1]].adj.append(self.uniq[e[0]])\n",
        "            \n",
        "    def bfs(self , start):\n",
        "        Q = Queue()\n",
        "        Q.put(start)\n",
        "        count = 0\n",
        "        start.visited = True\n",
        "        while(Q.empty() == False):\n",
        "            count = count + 1\n",
        "            current = Q.get()\n",
        "            for n in current.adj:\n",
        "                if(n.visited == False):\n",
        "                    Q.put(n)\n",
        "                    n.visited = True\n",
        "                \n",
        "        return count\n",
        "    def compare(self, A , B):\n",
        "        if(A[1] > B[1]):\n",
        "            return 1\n",
        "        elif(A[1] < B[1]):\n",
        "            return -1\n",
        "        else:\n",
        "            return 0\n",
        "        \n",
        "    def max_network(self):\n",
        "        vertices = self.uniq\n",
        "        for v in vertices:\n",
        "            if(vertices[v].visited == False):\n",
        "                self.cluster.append([v,self.bfs(vertices[v])])\n",
        "    def summary(self):\n",
        "        print(str(len(self.cluster)) + \" total clusters\")\n",
        "        return self.cluster\n",
        "    def reset(self):\n",
        "        for v in self.uniq:\n",
        "            self.uniq[v].visited = False\n",
        "       \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYdXmuhJjGI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g = my_graph(data)\n",
        "g.create_graph()\n",
        "g.max_network()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5TMpnHrlfEg",
        "colab_type": "text"
      },
      "source": [
        "The above code just created a non directional graph and counted the nodes in each strongly connected components for the graph. \n",
        "\n",
        "1.   let us first cluster according to the components \n",
        "2.   Two different clusters have no transactions to        link them so its point less to use them together      in a clusterring algorithm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoNE_oj_j-w3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr = g.cluster\n",
        "g.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "redYGbvUll0I",
        "colab_type": "text"
      },
      "source": [
        "\"arr\" contains [\"address\" , \"components_size\"]\n",
        "\n",
        "Because to access a strongly connected component only one node is enough\n",
        "\n",
        "now for this demonstration purpose i am intrested in all the component that are larger than 1000 nodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_fjDTFjkZQX",
        "colab_type": "code",
        "outputId": "e6fe979d-0a32-4cef-a9a3-a72cbc23419c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(\"node from scomponent            component size\")\n",
        "for c in arr:\n",
        "    if(c[1] > 1000):\n",
        "        print(c[0] , c[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "node from scomponent            component size\n",
            "16xXj3T5ujZ3LtxPNza7eEz6fbk62YiWb6 1488004\n",
            "1MaZAHzEFfinRJ2dwK6YtNDfvWMBkiAxDr 102643\n",
            "18ZDrJFNwynkdfGUhyHSmNCsbAdMhjDjHt 1916\n",
            "1Eu9LhFCcTTNjg7rTG84rgyNgNCFWxHkMG 1505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcDwfSSxwebr",
        "colab_type": "text"
      },
      "source": [
        "We have extracted address for all clusters that are over 1000 addresses....\n",
        "And look the largest cluster is 14 lac !!!\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "But at this point of time they are just random addresses...\n",
        "\n",
        "\n",
        "1.   We will now assign each node a 100 dimentional        vector\n",
        "2.   Then use random walks to generate sequences of addresses\n",
        "3. We will train and cluster addressed         according to these sequences formed. \n",
        "3.   The idea for node-to-vector is explored in    https://web.cs.wpi.edu/~xkong/publications/papers/cikm17.pdf\n",
        "4. I have explained the random walk in my report.\n",
        "5. There are several benefits of random\n",
        "walks over pure BFS/DFS approaches. Random walks are computationally efficient in terms of both space and time requirements.\n",
        "The space complexity to store the immediate neighbors of every\n",
        "node in the graph is O(|E|).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htS4rQailCn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Graph():\n",
        "\tdef __init__(self, nx_G, is_directed, p, q):\n",
        "\t\tself.G = nx_G\n",
        "\t\tself.is_directed = is_directed\n",
        "\t\tself.p = p\n",
        "\t\tself.q = q\n",
        "\n",
        "\tdef node2vec_walk(self, walk_length, start_node):\n",
        "\t\t'''\n",
        "\t\tSimulate a random walk starting from start node.\n",
        "\t\t'''\n",
        "\t\tG = self.G\n",
        "\t\talias_nodes = self.alias_nodes\n",
        "\t\talias_edges = self.alias_edges\n",
        "\n",
        "\t\twalk = [start_node]\n",
        "\n",
        "\t\twhile len(walk) < walk_length:\n",
        "\t\t\tcur = walk[-1]\n",
        "\t\t\tcur_nbrs = sorted(G.neighbors(cur))\n",
        "\t\t\tif len(cur_nbrs) > 0:\n",
        "\t\t\t\tif len(walk) == 1:\n",
        "\t\t\t\t\twalk.append(cur_nbrs[alias_draw(alias_nodes[cur][0], alias_nodes[cur][1])])\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tprev = walk[-2]\n",
        "\t\t\t\t\tnext = cur_nbrs[alias_draw(alias_edges[(prev, cur)][0], \n",
        "\t\t\t\t\t\talias_edges[(prev, cur)][1])]\n",
        "\t\t\t\t\twalk.append(next)\n",
        "\t\t\telse:\n",
        "\t\t\t\tbreak\n",
        "\n",
        "\t\treturn walk\n",
        "\n",
        "\tdef simulate_walks(self, num_walks, walk_length):\n",
        "\t\t'''\n",
        "\t\tRepeatedly simulate random walks from each node.\n",
        "\t\t'''\n",
        "\t\tG = self.G\n",
        "\t\twalks = []\n",
        "\t\tnodes = list(G.nodes())\n",
        "\t\tprint ('Walk iteration:')\n",
        "\t\tfor walk_iter in range(num_walks):\n",
        "\t\t\tprint (str(walk_iter+1), '/', str(num_walks))\n",
        "\t\t\trandom.shuffle(nodes)\n",
        "\t\t\tfor node in nodes:\n",
        "\t\t\t\twalks.append(self.node2vec_walk(walk_length=walk_length, start_node=node))\n",
        "\n",
        "\t\treturn walks\n",
        "\n",
        "\tdef get_alias_edge(self, src, dst):\n",
        "\t\t'''\n",
        "\t\tGet the alias edge setup lists for a given edge.\n",
        "\t\t'''\n",
        "\t\tG = self.G\n",
        "\t\tp = self.p\n",
        "\t\tq = self.q\n",
        "\n",
        "\t\tunnormalized_probs = []\n",
        "\t\tfor dst_nbr in sorted(G.neighbors(dst)):\n",
        "\t\t\tif dst_nbr == src:\n",
        "\t\t\t\tunnormalized_probs.append(G[dst][dst_nbr]['weight']/p)\n",
        "\t\t\telif G.has_edge(dst_nbr, src):\n",
        "\t\t\t\tunnormalized_probs.append(G[dst][dst_nbr]['weight'])\n",
        "\t\t\telse:\n",
        "\t\t\t\tunnormalized_probs.append(G[dst][dst_nbr]['weight']/q)\n",
        "\t\tnorm_const = sum(unnormalized_probs)\n",
        "\t\tnormalized_probs =  [float(u_prob)/norm_const for u_prob in unnormalized_probs]\n",
        "\n",
        "\t\treturn alias_setup(normalized_probs)\n",
        "\n",
        "\tdef preprocess_transition_probs(self):\n",
        "\t\t'''\n",
        "\t\tPreprocessing of transition probabilities for guiding the random walks.\n",
        "\t\t'''\n",
        "\t\tG = self.G\n",
        "\t\tis_directed = self.is_directed\n",
        "\n",
        "\t\talias_nodes = {}\n",
        "\t\tfor node in G.nodes():\n",
        "\t\t\tunnormalized_probs = [G[node][nbr]['weight'] for nbr in sorted(G.neighbors(node))]\n",
        "\t\t\tnorm_const = sum(unnormalized_probs)\n",
        "\t\t\tnormalized_probs =  [float(u_prob)/norm_const for u_prob in unnormalized_probs]\n",
        "\t\t\talias_nodes[node] = alias_setup(normalized_probs)\n",
        "\n",
        "\t\talias_edges = {}\n",
        "\t\ttriads = {}\n",
        "\n",
        "\t\tif is_directed:\n",
        "\t\t\tfor edge in G.edges():\n",
        "\t\t\t\talias_edges[edge] = self.get_alias_edge(edge[0], edge[1])\n",
        "\t\telse:\n",
        "\t\t\tfor edge in G.edges():\n",
        "\t\t\t\talias_edges[edge] = self.get_alias_edge(edge[0], edge[1])\n",
        "\t\t\t\talias_edges[(edge[1], edge[0])] = self.get_alias_edge(edge[1], edge[0])\n",
        "\n",
        "\t\tself.alias_nodes = alias_nodes\n",
        "\t\tself.alias_edges = alias_edges\n",
        "\n",
        "\t\treturn\n",
        "\n",
        "\n",
        "def alias_setup(probs):\n",
        "\tK = len(probs)\n",
        "\tq = np.zeros(K)\n",
        "\tJ = np.zeros(K, dtype=np.int)\n",
        "\n",
        "\tsmaller = []\n",
        "\tlarger = []\n",
        "\tfor kk, prob in enumerate(probs):\n",
        "\t    q[kk] = K*prob\n",
        "\t    if q[kk] < 1.0:\n",
        "\t        smaller.append(kk)\n",
        "\t    else:\n",
        "\t        larger.append(kk)\n",
        "\n",
        "\twhile len(smaller) > 0 and len(larger) > 0:\n",
        "\t    small = smaller.pop()\n",
        "\t    large = larger.pop()\n",
        "\n",
        "\t    J[small] = large\n",
        "\t    q[large] = q[large] + q[small] - 1.0\n",
        "\t    if q[large] < 1.0:\n",
        "\t        smaller.append(large)\n",
        "\t    else:\n",
        "\t        larger.append(large)\n",
        "\n",
        "\treturn J, q\n",
        "\n",
        "def alias_draw(J, q):\n",
        "\t'''\n",
        "\tDraw sample from a non-uniform discrete distribution using alias sampling.\n",
        "\t'''\n",
        "\tK = len(J)\n",
        "\n",
        "\tkk = int(np.floor(np.random.rand()*K))\n",
        "\tif np.random.rand() < q[kk]:\n",
        "\t    return kk\n",
        "\telse:\n",
        "\t    return J[kk]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR5JclTeyFC6",
        "colab_type": "text"
      },
      "source": [
        "**Now we will use a single node to get a particular component**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbj9GGe8x70Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function gets all the nodes in a strongly connected component\n",
        "def get_component_nodes(initial_address , graph):\n",
        "    graph.reset()\n",
        "    Q = Queue()\n",
        "    Q.put(graph.uniq[initial_address])\n",
        "    arr = [initial_address]\n",
        "    graph.uniq[initial_address].visited = True\n",
        "    while(Q.empty() == False):\n",
        "        current = Q.get()\n",
        "        arr.append(current.name)\n",
        "        for n in current.adj:\n",
        "            if(n.visited == False):\n",
        "                Q.put(n)\n",
        "                n.visited = True\n",
        "    return arr\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VskoVzQ50V-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr = get_component_nodes(\"18ZDrJFNwynkdfGUhyHSmNCsbAdMhjDjHt\" , g)  # selecting one of the components that have above 1000 nodes\n",
        "arr = set(arr)\n",
        "# arr now contains all the nodes in a connected component"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgAyPmU00eAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we now extract all the edges that have any nodes from the selected connected component\n",
        "processed_data = []\n",
        "for d in data:\n",
        "    if((d[0] in arr or d[1] in arr) and d[2] > 0):\n",
        "        processed_data.append(d)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_DaZ-9J03E4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c99af7eb-4968-4c73-8683-5e501167148c"
      },
      "source": [
        "G_raw = nx.Graph()   # defining a graph using networkx\n",
        "num_nodes = 10       # here num_nodes defines how many nodes do we cover for each random walk\n",
        "num_walks = 5        # total number of times all the nodes will be put through walk algo\n",
        "\n",
        "G_raw.add_weighted_edges_from(processed_data)\n",
        "G = Graph(G_raw, False,p =  1, q = .5)     # here p ,q  are hyper-parameters guiding the random walk\n",
        "G.preprocess_transition_probs()\n",
        "walks = G.simulate_walks(num_walks, num_nodes)\n",
        "walks = [list(map(str, walk)) for walk in walks]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello\n",
            "Walk iteration:\n",
            "1 / 5\n",
            "2 / 5\n",
            "3 / 5\n",
            "4 / 5\n",
            "5 / 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvXsNZRJtZ1Q",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "Now that we have sequence of addresses we sinmply feed them to gensim's wordtovector model.\n",
        "\n",
        "It applies CBOW model for learning node embeddings "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGk6IPCD1OvQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "11ac08a7-baf1-4755-9a15-06d19c01e203"
      },
      "source": [
        "model = Word2Vec(walks, size=100, window=5, min_count=0, sg=0, workers=5 , iter = 20)\n",
        "node_vectors = model.wv\n",
        "X = model[model.wv.vocab]\n",
        "#model.save(\"node2vec.model\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3F_cT1goOWa",
        "colab_type": "text"
      },
      "source": [
        "We have obtained 100 dimentional vectors for each node. now lets try to visualize this in 2 dimention using PCA  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "I have also used k means clustering and number of clusters has been set as 6. \n",
        "This is done to show the effectiveness of the method. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47wWH6Hc1abY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters = 6   \n",
        "km = KMeans(\n",
        "    n_clusters=n_clusters, init='random',\n",
        "    n_init=10, max_iter=3000, \n",
        "    tol=1e-04, random_state=0\n",
        ")\n",
        "y_km = km.fit_predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3EEmPpP1h1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "04951512-adb8-41bb-9e5c-12abfb62ae45"
      },
      "source": [
        "color = {0:\"orange\" , 1:\"black\" , 2:\"blue\" , 3:\"red\", 4:\"lightgreen\" , 5:\"pink\" , 6:\"yellow\"}\n",
        "pca = PCA(n_components=2)\n",
        "result = pca.fit_transform(X).tolist()\n",
        "for i in range(len(result)):\n",
        "    plt.scatter(result[i][0]  , result[i][1] , c = color[y_km[i]])\n",
        "    \n",
        "plt.show()    "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdZDI807sz1S",
        "colab_type": "text"
      },
      "source": [
        "**These are the results from clustering drawn on a 2-D plane**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n9jNfUlo1lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the mapping from all the addresses to their corrosponding vectors(embeddings)\n",
        "model[\"18ZDrJFNwynkdfGUhyHSmNCsbAdMhjDjHt\"].shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwseMPRfxLFB",
        "colab_type": "text"
      },
      "source": [
        "We have only trained one component yet!!!!\n",
        "Given more time i can use these trained features for other machine learning tasks.\n",
        "\n",
        "I hope you enjoyed the notebook !!!\n",
        "\n",
        "Thank you for reading\n",
        "\n",
        "until next time :)"
      ]
    }
  ]
}